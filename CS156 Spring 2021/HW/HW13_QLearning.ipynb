{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS156 (Introduction to AI), Spring 2021\n",
    "# <u> Homework 13 submission </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roster Name: Azael Zamora\n",
    "## Student ID: 013528931\n",
    "## Email Address: azael.zamora12@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> References and sources </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.kaggle.com/charel/learn-by-example-reinforcement-learning-with-gym\n",
    "* RL.Q-learning.taxi_game.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "l8zS7SWPoiiJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wizmM249owks"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgMliDeLqFxB"
   },
   "source": [
    "* S : starting point, safe\n",
    "* F : frozen surface, safe\n",
    "* H : hole, fall to your doom\n",
    "* G : goal, where the frisbee is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHzp-vsRo756",
    "outputId": "7fde524f-207e-4718-b3bc-eddeea2846e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "Action Space Discrete(4)\n",
      "State Space Discrete(16)\n"
     ]
    }
   ],
   "source": [
    "FrozenLakeEnv = gym.make(\"FrozenLake-v0\", is_slippery = False).env \n",
    "FrozenLakeEnv.seed(42)\n",
    "FrozenLakeEnv.reset()\n",
    "FrozenLakeEnv.render()\n",
    "\n",
    "print(\"Action Space {}\".format(FrozenLakeEnv.action_space))\n",
    "print(\"State Space {}\".format(FrozenLakeEnv.observation_space))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kp-MqP5CiJy"
   },
   "source": [
    "# Q-Learning Algorithm w/ Stochasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pKg3sy6PuyqR",
    "outputId": "d33c475f-8844-4db0-a86c-e71c8375ceaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100 Total Reward: 0.0\n",
      "Episode 200 Total Reward: 0.0\n",
      "Episode 300 Total Reward: 0.0\n",
      "Episode 400 Total Reward: 0.0\n",
      "Episode 500 Total Reward: 0.0\n",
      "Episode 600 Total Reward: 0.0\n",
      "Episode 700 Total Reward: 0.0\n",
      "Episode 800 Total Reward: 0.0\n",
      "Episode 900 Total Reward: 0.0\n",
      "Episode 1000 Total Reward: 0.0\n",
      "Episode 1100 Total Reward: 0.0\n",
      "Episode 1200 Total Reward: 0.0\n",
      "Episode 1300 Total Reward: 1.0\n",
      "Episode 1400 Total Reward: 1.0\n",
      "Episode 1500 Total Reward: 1.0\n",
      "Episode 1600 Total Reward: 0.0\n",
      "Episode 1700 Total Reward: 0.0\n",
      "Episode 1800 Total Reward: 1.0\n",
      "Episode 1900 Total Reward: 1.0\n",
      "Episode 2000 Total Reward: 0.0\n",
      "Episode 2100 Total Reward: 0.0\n",
      "Episode 2200 Total Reward: 0.0\n",
      "Episode 2300 Total Reward: 0.0\n",
      "Episode 2400 Total Reward: 0.0\n",
      "Episode 2500 Total Reward: 0.0\n",
      "Episode 2600 Total Reward: 1.0\n",
      "Episode 2700 Total Reward: 1.0\n",
      "Episode 2800 Total Reward: 0.0\n",
      "Episode 2900 Total Reward: 0.0\n",
      "Episode 3000 Total Reward: 1.0\n",
      "Episode 3100 Total Reward: 0.0\n",
      "Episode 3200 Total Reward: 0.0\n",
      "Episode 3300 Total Reward: 1.0\n",
      "Episode 3400 Total Reward: 0.0\n",
      "Episode 3500 Total Reward: 0.0\n",
      "Episode 3600 Total Reward: 0.0\n",
      "Episode 3700 Total Reward: 1.0\n",
      "Episode 3800 Total Reward: 0.0\n",
      "Episode 3900 Total Reward: 1.0\n",
      "Episode 4000 Total Reward: 1.0\n",
      "Episode 4100 Total Reward: 0.0\n",
      "Episode 4200 Total Reward: 1.0\n",
      "Episode 4300 Total Reward: 0.0\n",
      "Episode 4400 Total Reward: 0.0\n",
      "Episode 4500 Total Reward: 1.0\n",
      "Episode 4600 Total Reward: 0.0\n",
      "Episode 4700 Total Reward: 0.0\n",
      "Episode 4800 Total Reward: 1.0\n",
      "Episode 4900 Total Reward: 0.0\n",
      "Episode 5000 Total Reward: 0.0\n",
      "Episode 5100 Total Reward: 0.0\n",
      "Episode 5200 Total Reward: 1.0\n",
      "Episode 5300 Total Reward: 1.0\n",
      "Episode 5400 Total Reward: 1.0\n",
      "Episode 5500 Total Reward: 0.0\n",
      "Episode 5600 Total Reward: 1.0\n",
      "Episode 5700 Total Reward: 0.0\n",
      "Episode 5800 Total Reward: 1.0\n",
      "Episode 5900 Total Reward: 1.0\n",
      "Episode 6000 Total Reward: 0.0\n",
      "Episode 6100 Total Reward: 0.0\n",
      "Episode 6200 Total Reward: 0.0\n",
      "Episode 6300 Total Reward: 0.0\n",
      "Episode 6400 Total Reward: 0.0\n",
      "Episode 6500 Total Reward: 0.0\n",
      "Episode 6600 Total Reward: 0.0\n",
      "Episode 6700 Total Reward: 1.0\n",
      "Episode 6800 Total Reward: 0.0\n",
      "Episode 6900 Total Reward: 1.0\n",
      "Episode 7000 Total Reward: 0.0\n",
      "Episode 7100 Total Reward: 1.0\n",
      "Episode 7200 Total Reward: 0.0\n",
      "Episode 7300 Total Reward: 0.0\n",
      "Episode 7400 Total Reward: 1.0\n",
      "Episode 7500 Total Reward: 0.0\n",
      "Episode 7600 Total Reward: 0.0\n",
      "Episode 7700 Total Reward: 0.0\n",
      "Episode 7800 Total Reward: 0.0\n",
      "Episode 7900 Total Reward: 0.0\n",
      "Episode 8000 Total Reward: 0.0\n",
      "Episode 8100 Total Reward: 0.0\n",
      "Episode 8200 Total Reward: 0.0\n",
      "Episode 8300 Total Reward: 1.0\n",
      "Episode 8400 Total Reward: 0.0\n",
      "Episode 8500 Total Reward: 1.0\n",
      "Episode 8600 Total Reward: 1.0\n",
      "Episode 8700 Total Reward: 0.0\n",
      "Episode 8800 Total Reward: 1.0\n",
      "Episode 8900 Total Reward: 0.0\n",
      "Episode 9000 Total Reward: 1.0\n",
      "Episode 9100 Total Reward: 1.0\n",
      "Episode 9200 Total Reward: 1.0\n",
      "Episode 9300 Total Reward: 0.0\n",
      "Episode 9400 Total Reward: 0.0\n",
      "Episode 9500 Total Reward: 1.0\n",
      "Episode 9600 Total Reward: 1.0\n",
      "Episode 9700 Total Reward: 0.0\n",
      "Episode 9800 Total Reward: 1.0\n",
      "Episode 9900 Total Reward: 1.0\n",
      "Episode 10000 Total Reward: 0.0\n"
     ]
    }
   ],
   "source": [
    "qtable = np.zeros([FrozenLakeEnv.observation_space.n, FrozenLakeEnv.action_space.n])\n",
    "gamma = 0.95  # discount factor\n",
    "alpha = 0.01  # learning rate\n",
    "epsilon = 0.5 # threshold of stochasticity\n",
    "\n",
    "for episode in range(1, 10001):\n",
    "  done = False\n",
    "  reward_total = 0\n",
    "  state = FrozenLakeEnv.reset()\n",
    "\n",
    "  while done != True:\n",
    "    explore = np.random.uniform(0, 1)\n",
    "\n",
    "    if explore < epsilon:\n",
    "      action = FrozenLakeEnv.action_space.sample()  # explore\n",
    "    else:\n",
    "      action = np.argmax(qtable[state])  # exploitation\n",
    "    \n",
    "    state_tmp, reward, done, info = FrozenLakeEnv.step(action) # take the action\n",
    "    qtable[state, action] += alpha * (reward + gamma * np.max(qtable[state_tmp]) - qtable[state, action])\n",
    "    state = state_tmp\n",
    "    reward_total = reward_total + reward\n",
    "  \n",
    "  if episode % 100 == 0:\n",
    "    print('Episode {} Total Reward: {}'.format(episode,reward_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjFITf2Ti3_7",
    "outputId": "7e1aa9d0-dc22-43ad-b974-99a460e5b2bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-table after:\n",
      "[[0.73509188 0.77378094 0.69833257 0.73509188]\n",
      " [0.73509049 0.         0.61160817 0.62231666]\n",
      " [0.31120732 0.80272946 0.03373014 0.2451871 ]\n",
      " [0.1812748  0.         0.00223652 0.00347698]\n",
      " [0.77378051 0.81450625 0.         0.7350916 ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.90149722 0.         0.37150653]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.81449969 0.         0.857375   0.77377748]\n",
      " [0.81433136 0.90233415 0.9025     0.        ]\n",
      " [0.85661431 0.95       0.         0.85011613]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.8223116  0.94999733 0.75812   ]\n",
      " [0.90119149 0.94882531 1.         0.90185454]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('Q-table after:')\n",
    "print(qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSLzj1DwkGnO",
    "outputId": "6f2744d7-3674-454f-ccb0-f60beaaf7bf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "Reward:  1.0\n"
     ]
    }
   ],
   "source": [
    "reward_total = 0\n",
    "state = FrozenLakeEnv.reset()\n",
    "done = False\n",
    "\n",
    "FrozenLakeEnv.render()\n",
    "\n",
    "while done != True:\n",
    "  action = np.argmax(qtable[state])\n",
    "  state, reward, done, info = FrozenLakeEnv.step(action)\n",
    "  reward_total += reward \n",
    "  FrozenLakeEnv.render()\n",
    "\n",
    "print(\"Reward: \", reward_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-WzGbb6Eve-x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW13_QLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
